# Task1

Применили несколько базовых аугментаций и визуализировали их действие:
    
    1. RandomHorizontalFlip: 
        
        --Изменяет ориентацию изображения горизонтально
        --Помогает модели учитывать симметричные особенности объекта (например, лица или других симметричных элементов)
    2. ColorJitter: 
        --Меняет яркость, контрастность, насыщенность и цветовой тон изображения
        --Увеличивает разнообразие данных, особенно полезно для задач, где важны цветовые характеристики
    3. RandomCrop: 
        --Вырезает случайный фрагмент изображения
        --Позволяет модель учиться на различных частях объекта, что помогает обобщению
    4. RandomRotation: 
        --Вращает изображение на случайный угол
        --Добавляет вариативность ориентации объекта, что важно для моделей, работающих с поворотами объектов
    5. RandomGrayscale: 
        Преобразует цветное изображение в черно-белое
        Полезно для задач, где цвет не является ключевым признаком
         
Комбинированные аугментации - На последнем графике показаны комбинации нескольких аугментаций (Combined #1, Combined #2, Combined #3, Combined #4): 
    
    --Каждая комбинация создает уникальное преобразование исходного изображения
    --Такой подход увеличивает разнообразие данных еще больше, так как каждая комбинация добавляет новые виды изменений
     
Вывод: Аугментации работают корректно; графики визуализаций показывают, что аугментации корректно увеличивают разнообразие данных, не искажая их суть. Можно дополнительно протестировать недостающие аугментации (RandomBlur, RandomPerspective, RandomBrightnessContrast)

# Task2

Выбраны классы: ['Гароу', 'Генос', 'Сайтама', 'Соник', 'Татсумаки']

Класс: Гароу

Для RandomBlur нет аналога в extra_augs
Для RandomPerspective нет аналога в extra_augs
Для RandomBrightnessContrast нет аналога в extra_augs

Класс: Генос

Для RandomBlur нет аналога в extra_augs
Для RandomPerspective нет аналога в extra_augs
Для RandomBrightnessContrast нет аналога в extra_augs

Класс: Сайтама

Для RandomBlur нет аналога в extra_augs
Для RandomPerspective нет аналога в extra_augs
Для RandomBrightnessContrast нет аналога в extra_augs

Класс: Соник

Для RandomBlur нет аналога в extra_augs
Для RandomPerspective нет аналога в extra_augs
Для RandomBrightnessContrast нет аналога в extra_augs

Класс: Татсумаки

Для RandomBlur нет аналога в extra_augs
Для RandomPerspective нет аналога в extra_augs
Для RandomBrightnessContrast нет аналога в extra_augs

Вывод: Для каждого класса были проверены три типа аугментаций (RandomBlur, RandomPerspective, RandomBrightnessContrast), но все они отсутствуют в дополнительных аугментациях 

# Task3

Количество изображений по классам:
  
  Гароу: 20
  Генос: 20
  Сайтама: 20
  Соник: 20
  Татсумаки: 20
  Фубуки: 20

Размеры изображений (ширина x высота):
  
  Минимальный размер: 270 x 258
  Максимальный размер: 736 x 1308
  Средний размер: 546.3 x 639.4

Вывод: Различия в размерах изображений могут потребовать предварительной обработки (например, ресайзинг) перед обучением модели

# Task4

Применение конфигурации: light

Аугментации в пайплайне: ['RandomHorizontalFlip']
Результаты конфигурации 'light' сохранены в results\augmented_light

Применение конфигурации: medium

Аугментации в пайплайне: ['RandomHorizontalFlip', 'RandomCrop', 'ColorJitter']
Результаты конфигурации 'medium' сохранены в results\augmented_medium

Применение конфигурации: heavy

Аугментации в пайплайне: ['RandomHorizontalFlip', 'RandomCrop', 'ColorJitter', 'RandomRotation', 'RandomGrayscale']
Результаты конфигурации 'heavy' сохранены в results\augmented_heavy

Все конфигурации успешно применены и сохранены в папку results/

Вывод: Heavy-конфигурация даёт наибольшее разнообразие, но требует проверки на валидационных метриках, чтобы не переусложнить данные

# Task5

Найдено 100 изображений для эксперимента.

Эксперимент для размера 64x64
Время: 1.01 сек | Память: 0.68 МБ

Эксперимент для размера 128x128
Время: 1.10 сек | Память: 0.19 МБ

Эксперимент для размера 224x224
Время: 1.17 сек | Память: 0.39 МБ

Эксперимент для размера 512x512
Время: 1.70 сек | Память: 1.60 МБ

Сохранено: experiment_time_vs_size.png
Сохранено: experiment_memory_vs_size.png

Эксперимент завершен. Графики сохранены в папку plots/

Вывод: Оптимальным является размер 224×224 — хороший баланс между качеством и ресурсами

# Task6

Эпоха 1/10
Train Loss: 1.4688 | Acc: 0.3667
Val   Loss: 2.6597 | Acc: 0.3333

Эпоха 2/10
Train Loss: 0.2213 | Acc: 0.9333
Val   Loss: 3.6864 | Acc: 0.4167

Эпоха 3/10
Train Loss: 0.1673 | Acc: 0.9583
Val   Loss: 2.7690 | Acc: 0.4167

Эпоха 4/10
Train Loss: 0.1064 | Acc: 0.9583
Val   Loss: 2.4286 | Acc: 0.4583

Эпоха 5/10
Train Loss: 0.0365 | Acc: 0.9917
Val   Loss: 2.7858 | Acc: 0.3750

Эпоха 6/10
Train Loss: 0.0683 | Acc: 0.9750
Val   Loss: 3.0982 | Acc: 0.6250

Эпоха 7/10
Train Loss: 0.0273 | Acc: 0.9917
Val   Loss: 3.8868 | Acc: 0.5833

Эпоха 8/10
Train Loss: 0.0373 | Acc: 0.9833
Val   Loss: 1.6979 | Acc: 0.6250

Эпоха 9/10
Train Loss: 0.0264 | Acc: 0.9917
Val   Loss: 1.5379 | Acc: 0.6667

Эпоха 10/10
Train Loss: 0.0209 | Acc: 1.0000
Val   Loss: 1.6041 | Acc: 0.6250

Сохранено: loss_curves.png
Сохранено: accuracy_curves.png

Обучение завершено. Модель и графики сохранены в results/.

Кратко о том, что сделано:

    --Дообучила предобученную ResNet18, заменив выходной слой под 5 классов (обучала на cpu)
    --На обучающей выборке точность достигла 100%, на валидационной — максимум около 66%
    --На графиках заметно переобучение: разрыв между обучающими и валидационными метриками

Вывод: Модель переобучается к концу обучения (высокая разница между Train и Val метриками). Что можно изменить, чтобы избежать этого?: 
    
    --Остановить обучение на 9-й эпохе, где Val Accuracy максимальна (~0.6667), тк на 10ой эпохе точность резко снижается
    --Применить регуляризацию или другие методы борьбы с переобучением
    --Увеличить объем данных или использовать более сложные аугментации
     

# 1.1 Сравнение на MNIST

Сверточная сеть (CNN) показала себя лучше на задаче классификации: она дала более высокую точность и меньшие ошибки на тестовых данных по сравнению с полносвязной сетью

Зато полносвязная сеть обучается быстрее и быстрее работает при прогнозировании, но по качеству она заметно уступает

Сверточная сеть с residual-блоками интересна тем, что у неё меньше параметров — это экономит память. Но за это приходится платить временем: она дольше обучается и дольше делает предсказания

Вывод: CNN — лучший выбор по точности, полносвязная — если важна скорость, а CNN с residual — если нужно экономить память

# 1.2 Сравнение на CIFAR-10

Сверточная сеть (CNN)
--Лучше справляется с задачей классификации: даёт более высокую точность и меньше ошибок на тесте
--По качеству заметно обходит полносвязную сеть

Полносвязная сеть
--Быстро обучается и быстро делает прогнозы
--Но по качеству сильно уступает CNN

Сверточная сеть с residual-блоками
--Требует меньше памяти за счёт меньшего числа параметров
--Но за это платим временем: дольше обучается и медленнее предсказывает

Вывод:
--Для лучшей точности — берём CNN
--Если важна скорость обучения и работы — подойдёт полносвязная сеть
--Если нужно экономить память — стоит выбрать CNN с residual-блоками

# 2.1 Влияние размера ядра свертки

Сверточные ядра разного размера ведут себя по-разному:
--Маленькие ядра (3x3, 5x5) хорошо замечают мелкие детали и текстуры
--Большие ядра (7x7) больше смотрят на общую картину и крупные элементы

Все модели нормально обучаются:
--Потери на обучении и тесте уменьшаются, точность растет
--Разрыв между обучением и тестом небольшой, значит, переобучения почти нет

Что выбрать:
--Если важны мелкие детали на картинках — лучше ядра 3x3 или 5x5
--Если важны общие формы и большие объекты — подойдут ядра 7x7

Вывод: модели стабильны, обучаются адекватно и показывают хорошие результаты как на обучающей, так и на тестовой выборках

# 2.2 Влияние глубины CNN

Чем глубже модель, тем сложнее и «живее» ведут себя градиенты:
--ResNet CNN — самая динамичная, градиенты сильно колеблются, но не затухают совсем благодаря residual-связям
--Deep CNN — тоже глубокая, но градиенты быстро стабилизируются после начала обучения
--Medium CNN — что-то среднее: заметные колебания, но не так выражены
--Shallow CNN — самая простая и стабильная по градиентам, но не такая «умная» для сложных задач

Чем меньше глубина, тем проще обучать сеть, но тем меньше она умеет

Что выбрать:
--Для сложных задач лучше глубокие модели вроде ResNet
--Если данные простые или мало ресурсов — подойдет Shallow CNN
--Если хочется компромисс — можно взять Medium CNN

# 3.1 Реализация кастомных слоев 

Pooling:
--Стандартный (AvgPool) — даёт ровные и стабильные значения, всё выглядит спокойно и равномерно
--Пользовательский (CustomPooling) — значения больше «разбросаны» и сильнее варьируются, возможно, лучше сохраняет детали

Сверточные слои:
--Стандартный (Conv2d) — чётко выделяет важные зоны на картинке, активации сосредоточены в ключевых местах
--Пользовательский (CustomConv2d) — активации более равномерно распределены по всей картинке, нет сильных пиков

Что выбрать:
--Если задача — находить конкретные признаки и фокусироваться на них, лучше стандартные (Conv2d + AvgPool)
--Если хочется больше информации и, возможно, лучше обобщение — попробуйте пользовательские (CustomConv2d + CustomPooling)

# 3.2 Эксперименты с Residual блоками

WideBlock:
--Быстро и стабильно обучается
--Самые низкие потери к концу и высокая точность
--Хорошо подходит для задач, где важна эффективность обучения

BasicBlock:
--Схожее поведение с WideBlock
--Тоже достигает высокой точности (~0.6) и показывает стабильность
--Отличный выбор, если нужна простота и надежность

BottleneckBlock:
--Стартует хуже остальных (высокие потери, низкая точность)
--Обучается медленнее, конечная точность ниже (~0.35)
--Может подойти, если приоритет — экономия ресурсов, но требует доработки и больше эпох

Что выбрать:
--Для быстрой и качественной работы: WideBlock или BasicBlock
--Если важны экономия памяти/вычислений: можно попробовать BottleneckBlock, но придётся поработать над гиперпараметрами и обучением
